{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've integrated the data and took a look at some of the outstanding factors such as missing values. We are good to proceed to testing out models. Some models that would probably work well: \n",
    "1. Baseline/naive neural network softmax as baseline\n",
    "1. Vanilla CNN with different pooling + batch normalization\n",
    "1. Advanced image detection algorithms such as AlexNet, LeNet, ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Split Training and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "import os \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suite_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>code</th>\n",
       "      <th>value</th>\n",
       "      <th>character</th>\n",
       "      <th>class</th>\n",
       "      <th>img_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>9</td>\n",
       "      <td>input_1_1_10</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>9</td>\n",
       "      <td>input_1_10_10</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>9</td>\n",
       "      <td>input_1_2_10</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>9</td>\n",
       "      <td>input_1_3_10</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>9</td>\n",
       "      <td>input_1_4_10</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   suite_id  sample_id  code  value character  class       img_name  width  \\\n",
       "0         1          1    10      9         九      9   input_1_1_10     64   \n",
       "1         1         10    10      9         九      9  input_1_10_10     64   \n",
       "2         1          2    10      9         九      9   input_1_2_10     64   \n",
       "3         1          3    10      9         九      9   input_1_3_10     64   \n",
       "4         1          4    10      9         九      9   input_1_4_10     64   \n",
       "\n",
       "   height  \n",
       "0      64  \n",
       "1      64  \n",
       "2      64  \n",
       "3      64  \n",
       "4      64  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/raw/chinese_mnist_classes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class that uses the dataset \n",
    "class ChineseMNISTDataset(Dataset): \n",
    "    def __init__(self, csv_file, root_dir, transform=None): \n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir \n",
    "        self.transform = transform\n",
    "    def __len__(self): \n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        # load the image name\n",
    "        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx]['img_name'] + '.jpg')\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        label = int(self.annotations.iloc[idx]['class'])\n",
    "        \n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../data/raw/images'\n",
    "csv_file = '../data/raw/chinese_mnist_classes.csv'\n",
    "\n",
    "dataset = ChineseMNISTDataset(csv_file=csv_file, root_dir=root_dir, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 64, 64])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "sample_loader = DataLoader(dataset, batch_size = 4, shuffle=True)\n",
    "for images,labels in sample_loader: \n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset and we are able to split into train and test data sets. Let us do do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size \n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader=DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Simple NN Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple linear softmax neural network model just to check some baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class nn_softmax_baseline(nn.Module): \n",
    "    def __init__(self, height, width, num_classes): \n",
    "        super(nn_softmax_baseline, self).__init__()\n",
    "        self.fc = nn.Linear(height * width, num_classes)\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, x): \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs=10,  train_loader=train_loader, test_loader=test_loader, learning_rate= 0.001, device=device): \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    \n",
    "    train_losses = [] \n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "        total_loss_tr = 0\n",
    "        total_tr_predictions = 0 \n",
    "        total_tr_correct = 0\n",
    "        for (images, labels) in train_loader: \n",
    "            images,labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss_tr+=loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_tr_predictions+=labels.size(0)\n",
    "            total_tr_correct +=(predicted == labels).sum().item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()          \n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad(): \n",
    "            total_t_loss = 0\n",
    "            total_predictions = 0 \n",
    "            correct_predictions = 0\n",
    "            for images, labels in test_loader: \n",
    "                images,labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_t_loss+=loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_predictions+=labels.size(0)\n",
    "                correct_predictions +=(predicted == labels).sum().item()\n",
    "        \n",
    "        train_losses.append(total_loss_tr/len(train_loader))\n",
    "        test_losses.append(total_t_loss/len(test_loader))\n",
    "        test_accuracy = correct_predictions/total_predictions\n",
    "        train_accuracy = total_tr_correct/total_tr_predictions\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        print(f\"Train Loss: {total_loss_tr/len(train_loader)}\")\n",
    "        print(f\"Test Loss: {total_t_loss/len(test_loader)}\")\n",
    "        print(f\"Train Accuracy: {train_accuracy}\")\n",
    "        print(f\"Test Accuracy: {test_accuracy}\")\n",
    "        print()\n",
    "        \n",
    "    return model, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 2.47991184985384\n",
      "Test Loss: 2.3274452884991965\n",
      "Train Accuracy: 0.21591666666666667\n",
      "Test Accuracy: 0.3416666666666667\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 2.1996408498033566\n",
      "Test Loss: 2.154573361078898\n",
      "Train Accuracy: 0.398\n",
      "Test Accuracy: 0.41233333333333333\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 2.0489703835325037\n",
      "Test Loss: 2.055066933234533\n",
      "Train Accuracy: 0.45575\n",
      "Test Accuracy: 0.44966666666666666\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 1.950087622125098\n",
      "Test Loss: 1.990242376923561\n",
      "Train Accuracy: 0.4821666666666667\n",
      "Test Accuracy: 0.4663333333333333\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 1.8787282159987917\n",
      "Test Loss: 1.9429818938175838\n",
      "Train Accuracy: 0.5024166666666666\n",
      "Test Accuracy: 0.471\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 1.822484864833507\n",
      "Test Loss: 1.9091433236996334\n",
      "Train Accuracy: 0.5159166666666667\n",
      "Test Accuracy: 0.479\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 1.7770469784736633\n",
      "Test Loss: 1.8820263743400574\n",
      "Train Accuracy: 0.5263333333333333\n",
      "Test Accuracy: 0.48233333333333334\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 1.7383843254535756\n",
      "Test Loss: 1.8603791048129399\n",
      "Train Accuracy: 0.5340833333333334\n",
      "Test Accuracy: 0.494\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 1.7042994423115507\n",
      "Test Loss: 1.8435491075118382\n",
      "Train Accuracy: 0.5403333333333333\n",
      "Test Accuracy: 0.493\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 1.675090674390184\n",
      "Test Loss: 1.8288375586271286\n",
      "Train Accuracy: 0.5485\n",
      "Test Accuracy: 0.49566666666666664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_model = nn_softmax_baseline(64, 64, 15)\n",
    "_, baseline_tr, baseline_t = train_model(baseline_model, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Vanilla CNN Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we test out vanilla cnn networks, those of which will implement just convolution, convolution with pooling, and batch normalization, dropout, other factors <br>\n",
    "\n",
    "Our goal is to outperform the baseline model, which captures no spatial invariance/equivariance of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanilla_cnn(nn.Module): \n",
    "    def __init__(self, num_classes): \n",
    "        super(vanilla_cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64*16*16, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 1.9464068121098457\n",
      "Test Loss: 1.3930198748906453\n",
      "Train Accuracy: 0.3888333333333333\n",
      "Test Accuracy: 0.5736666666666667\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.9742066612903107\n",
      "Test Loss: 0.7541897793610891\n",
      "Train Accuracy: 0.7063333333333334\n",
      "Test Accuracy: 0.76\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.5693226938552045\n",
      "Test Loss: 0.4977073259651661\n",
      "Train Accuracy: 0.816\n",
      "Test Accuracy: 0.8403333333333334\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.39931658956598726\n",
      "Test Loss: 0.40543611099322635\n",
      "Train Accuracy: 0.8729166666666667\n",
      "Test Accuracy: 0.8543333333333333\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.2964889812976756\n",
      "Test Loss: 0.30255187427004177\n",
      "Train Accuracy: 0.9056666666666666\n",
      "Test Accuracy: 0.909\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.22684275010164748\n",
      "Test Loss: 0.24922095922132334\n",
      "Train Accuracy: 0.9291666666666667\n",
      "Test Accuracy: 0.925\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.17697744348898847\n",
      "Test Loss: 0.25416907481849194\n",
      "Train Accuracy: 0.94825\n",
      "Test Accuracy: 0.9223333333333333\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.14692367145672758\n",
      "Test Loss: 0.2045219587162137\n",
      "Train Accuracy: 0.9568333333333333\n",
      "Test Accuracy: 0.9303333333333333\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.12465175732653191\n",
      "Test Loss: 0.20689815003424883\n",
      "Train Accuracy: 0.9618333333333333\n",
      "Test Accuracy: 0.932\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.10699632371518206\n",
      "Test Loss: 0.2099224099268516\n",
      "Train Accuracy: 0.96675\n",
      "Test Accuracy: 0.929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_cnn = vanilla_cnn(15)\n",
    "_, baseline_cnn_tr, baseline_cnn_t = train_model(baseline_cnn, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Transfer Learning Using Pretrained Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.5459261225100528\n",
      "Test Loss: 0.15133033708358803\n",
      "Train Accuracy: 0.82175\n",
      "Test Accuracy: 0.951\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.09516149787034126\n",
      "Test Loss: 1.3060758287707965\n",
      "Train Accuracy: 0.9704166666666667\n",
      "Test Accuracy: 0.6793333333333333\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.0685760673294042\n",
      "Test Loss: 0.244675158833464\n",
      "Train Accuracy: 0.978\n",
      "Test Accuracy: 0.9253333333333333\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.045600317453252194\n",
      "Test Loss: 0.15023984014987946\n",
      "Train Accuracy: 0.9855833333333334\n",
      "Test Accuracy: 0.951\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.049547036143733146\n",
      "Test Loss: 0.1523511977866292\n",
      "Train Accuracy: 0.9849166666666667\n",
      "Test Accuracy: 0.961\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.024462277624518313\n",
      "Test Loss: 0.15614262782037258\n",
      "Train Accuracy: 0.9926666666666667\n",
      "Test Accuracy: 0.957\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.0207369190658086\n",
      "Test Loss: 0.050020152780537806\n",
      "Train Accuracy: 0.994\n",
      "Test Accuracy: 0.9843333333333333\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.03634533886872034\n",
      "Test Loss: 0.15214982318381468\n",
      "Train Accuracy: 0.9881666666666666\n",
      "Test Accuracy: 0.9553333333333334\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.025277639283461772\n",
      "Test Loss: 0.09269596651817362\n",
      "Train Accuracy: 0.99175\n",
      "Test Accuracy: 0.973\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.013409189480490627\n",
      "Test Loss: 0.5156137309968472\n",
      "Train Accuracy: 0.9953333333333333\n",
      "Test Accuracy: 0.861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 4: Transfer Learning Using ResNet18\n",
    "from torchvision import models \n",
    "resnet18 = models.resnet18()\n",
    "num_classes = 15\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
    "\n",
    "_, resnet18_tr, resnet18_t = train_model(resnet18, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
